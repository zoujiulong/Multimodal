{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3YK8rvgPp31duYUkdMZzI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zoujiulong/Multimodal/blob/main/Score_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrgkYFYtF68V"
      },
      "outputs": [],
      "source": [
        "!pip install -q omegaconf torchvision tqdm matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# class TimeEmedding(nn.Module):\n",
        "#     def __init__(self,in_channel):\n",
        "#         super().__init__()\n",
        "#         self.in_channel=in_channel\n",
        "#         self.proj1=nn.Linear(in_channel//4,in_channel)\n",
        "#         self.act1=nn.ELU()\n",
        "#         self.proj2=nn.Linear(in_channel,in_channel)\n",
        "#     def forward(self,t):\n",
        "#         print('t',t.shape)\n",
        "#         # t_emb=torch.empty((*t.shape[:-1],self.in_channel//4))\n",
        "#         print('t_emb',t_emb.shape)\n",
        "#         emb=math.log(10000)/(self.in_channel//8)\n",
        "#         emb=t[:,None]*torch.exp(torch.arange(self.in_channel//8)*-emb)\n",
        "#         print('emb',emb.shape)\n",
        "#         t_emb[:,:,:,::2]=emb.sin()\n",
        "#         t_emb[:,:,:,1::2]=emb.cos()\n",
        "#         t_emb=self.proj1(t_emb)\n",
        "#         t_emb=self.act1(t_emb)\n",
        "#         t_emb=self.proj2(t_emb)\n",
        "#         return t_emb\n",
        "class Swish(nn.Module):\n",
        "    \"\"\"\n",
        "    ### Swish activation function\n",
        "\n",
        "    $$x \\cdot \\sigma(x)$$\n",
        "    \"\"\"\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * torch.sigmoid(x)\n",
        "class TimeEmbedding(nn.Module):\n",
        "    \"\"\"\n",
        "    ### Embeddings for $t$\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_channels: int):\n",
        "        \"\"\"\n",
        "        * `n_channels` is the number of dimensions in the embedding\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.n_channels = n_channels\n",
        "        # First linear layer\n",
        "        self.lin1 = nn.Linear(self.n_channels // 4, self.n_channels)\n",
        "        # Activation\n",
        "        self.act = Swish()\n",
        "        # Second linear layer\n",
        "        self.lin2 = nn.Linear(self.n_channels, self.n_channels)\n",
        "\n",
        "    def forward(self, t: torch.Tensor):\n",
        "        # Create sinusoidal position embeddings\n",
        "        # [same as those from the transformer](../../transformers/positional_encoding.html)\n",
        "        #\n",
        "        # \\begin{align}\n",
        "        # PE^{(1)}_{t,i} &= sin\\Bigg(\\frac{t}{10000^{\\frac{i}{d - 1}}}\\Bigg) \\\\\n",
        "        # PE^{(2)}_{t,i} &= cos\\Bigg(\\frac{t}{10000^{\\frac{i}{d - 1}}}\\Bigg)\n",
        "        # \\end{align}\n",
        "        #\n",
        "        # where $d$ is `half_dim`\n",
        "        half_dim = self.n_channels // 8\n",
        "        emb = math.log(10_000) / (half_dim - 1)\n",
        "        emb = torch.exp(torch.arange(half_dim, device=t.device) * -emb)\n",
        "        emb = t[:, None] * emb[None, :]\n",
        "        emb = torch.cat((emb.sin(), emb.cos()), dim=1)\n",
        "\n",
        "        # Transform with the MLP\n",
        "        emb = self.act(self.lin1(emb))\n",
        "        emb = self.lin2(emb)\n",
        "\n",
        "        #\n",
        "        return emb\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self,head_num,ch,p=0.1):\n",
        "        super().__init__()\n",
        "        self.head_num=head_num\n",
        "        self.head_dim=ch//head_num\n",
        "        self.qkv=nn.Linear(ch,3*ch)\n",
        "        self.softmax=nn.Softmax()\n",
        "        self.drop1=nn.Dropout(p)\n",
        "        self.linear=nn.Linear(ch,ch)\n",
        "        self.drop2=nn.Dropout(p)\n",
        "    def forward(self,x):\n",
        "        bs,ch,h,w=x.shape\n",
        "        out=x.view(bs,ch,-1).permute(0,2,1)\n",
        "        out=self.qkv(out).view(bs,-1,self.head_num,3*self.head_dim).permute(0,2,1,3)\n",
        "        q,k,v=torch.chunk(out,3,dim=-1)\n",
        "        k=torch.transpose(k,-2,-1)\n",
        "        inter=(q@k)/(self.head_dim)**0.5\n",
        "        inter=self.drop1(self.softmax(inter))\n",
        "        o=inter@v\n",
        "        o=o.permute(0,2,1,3).contiguous()\n",
        "        o=o.view(bs,h*w,-1)\n",
        "        o=self.drop2(self.linear(o))\n",
        "        o=o.permute(0,2,1).view(bs,-1,h,w)+x\n",
        "        return o\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self,in_channel,out_channel,time_channel,n_groups=32,p=0.1):\n",
        "        super().__init__()\n",
        "        self.in_ch=in_channel\n",
        "        # self.ins1=nn.InstanceNorm2d(in_channel)\n",
        "        self.ins1=nn.GroupNorm(n_groups, in_channel)\n",
        "        # self.act1=nn.ELU()\n",
        "        self.act1=Swish()\n",
        "        self.conv1=nn.Conv2d(in_channel,out_channel,kernel_size=(3,3),padding=1)\n",
        "        # self.ins2=nn.InstanceNorm2d(in_channel)\n",
        "        self.ins2=nn.GroupNorm(n_groups, out_channel)\n",
        "        self.act2=Swish()\n",
        "        self.conv2=nn.Conv2d(out_channel,out_channel,kernel_size=(3,3),padding=1)\n",
        "        if in_channel!=out_channel:\n",
        "            self.residual=nn.Conv2d(in_channel,out_channel,kernel_size=(1,1))\n",
        "        else:\n",
        "            self.residual=nn.Identity()\n",
        "        self.time_emb = nn.Linear(time_channel, out_channel)\n",
        "        self.time_act = Swish()\n",
        "        self.dropout = nn.Dropout(p)\n",
        "    def forward(self,img,t):\n",
        "        out=self.conv1(self.act1(self.ins1(img)))\n",
        "        print('out',out.shape)\n",
        "        # out+=self.time_emb(self.time_act(t)).permute(0,3,1,2)\n",
        "        if t is not None:\n",
        "          out+=self.time_emb(self.time_act(t))[:, :, None, None]\n",
        "        out=self.conv2(self.dropout(self.act2(self.ins2(out))))\n",
        "        out+=self.residual(img)\n",
        "        return out\n",
        "\n",
        "class DownBlock(nn.Module):\n",
        "    def __init__(self,in_channel,out_channel,time_channel,head_num,has_attention=False):\n",
        "        super().__init__()\n",
        "        self.residual=ResidualBlock(in_channel,out_channel,time_channel)\n",
        "        if has_attention:\n",
        "            self.attention=Attention(head_num,out_channel)\n",
        "        else:\n",
        "            self.attention=nn.Identity()\n",
        "    def forward(self,img,t):\n",
        "        out=self.residual(img,t)\n",
        "        out=self.attention(out)\n",
        "        return out\n",
        "\n",
        "class MiddleBlock(nn.Module):\n",
        "    def __init__(self,in_channel,out_channel,time_channel,head_num):\n",
        "        super().__init__()\n",
        "        self.residual1=ResidualBlock(in_channel,out_channel,time_channel)\n",
        "        self.attention=Attention(head_num,out_channel)\n",
        "        self.residual2=ResidualBlock(out_channel,out_channel,time_channel)\n",
        "    def forward(self,img,t):\n",
        "        out=self.residual1(img,t)\n",
        "        out=self.attention(out)\n",
        "        print('attention')\n",
        "        out=self.residual2(out,t)\n",
        "        return out\n",
        "\n",
        "class UpBlock(nn.Module):\n",
        "    def __init__(self,in_channel,out_channel,time_channel,head_num,has_attention=False):\n",
        "        super().__init__()\n",
        "        self.residual=ResidualBlock(in_channel+out_channel,out_channel,time_channel)\n",
        "        if has_attention:\n",
        "            self.attention=Attention(head_num,out_channel)\n",
        "        else:\n",
        "            self.attention=nn.Identity()\n",
        "    def forward(self,img,t):\n",
        "        out=self.residual(img,t)\n",
        "        out=self.attention(out)\n",
        "        return out\n",
        "\n",
        "class DownSampleBlock(nn.Module):\n",
        "    def __init__(self,in_channel):\n",
        "        super().__init__()\n",
        "        self.conv=nn.Conv2d(in_channel,in_channel,kernel_size=(3,3),stride=(2,2),padding=(1,1))\n",
        "    def forward(self,img,t):\n",
        "        _=t\n",
        "        return self.conv(img)\n",
        "\n",
        "class UpSampleBlock(nn.Module):\n",
        "    def __init__(self,in_channel):\n",
        "        super().__init__()\n",
        "        self.conv=nn.ConvTranspose2d(in_channel,in_channel,kernel_size=(4,4),stride=(2,2),padding=(1,1))\n",
        "    def forward(self,img,t):\n",
        "        _=t\n",
        "        return self.conv(img)\n",
        "\n",
        "class Unet(nn.Module):\n",
        "    def __init__(self,layers,img_ch=1,in_channel=64,blocks=2,head_num=8):\n",
        "        super().__init__()\n",
        "        down=[]\n",
        "        coe=(1,2,2,4)\n",
        "        self.conv1=nn.Conv2d(img_ch,in_channel,kernel_size=(3,3),padding=(1,1))\n",
        "        self.time=TimeEmbedding(in_channel*4)\n",
        "        n_channel=in_channel\n",
        "        for i in range(layers):\n",
        "            out_ch=coe[i]*in_channel\n",
        "            # print(out_ch)\n",
        "            # print(in_channel)\n",
        "            for _ in range(blocks):\n",
        "                down.append(DownBlock(in_channel,out_ch,n_channel*4,head_num))\n",
        "                in_channel=out_ch\n",
        "            # print(in_channel)\n",
        "            # print(out_ch)\n",
        "            if i<layers-1:\n",
        "                down.append(DownSampleBlock(out_ch))\n",
        "        self.down=nn.ModuleList(down)\n",
        "        self.middle=MiddleBlock(out_ch,out_ch,n_channel*4,head_num)\n",
        "        up=[]\n",
        "        in_channel=out_ch\n",
        "        for i in range(layers):\n",
        "            out_ch=in_channel\n",
        "            for _ in range(blocks):\n",
        "                up.append(UpBlock(in_channel,out_ch,n_channel*4,head_num))\n",
        "            out_ch=in_channel//coe[layers-1-i]\n",
        "            up.append(UpBlock(in_channel,out_ch,n_channel*4,head_num))\n",
        "            in_channel=out_ch\n",
        "            if i<layers-1:\n",
        "                up.append(UpSampleBlock(in_channel))\n",
        "        self.up=nn.ModuleList(up)\n",
        "        # self.ins=nn.InstanceNorm2d(in_channel)\n",
        "        self.ins=nn.GroupNorm(8, n_channel)\n",
        "\n",
        "        # self.act=nn.ELU()\n",
        "        self.act=Swish()\n",
        "        self.conv2=nn.Conv2d(in_channel,img_ch,kernel_size=(3,3),padding=(1,1))\n",
        "    def forward(self,x,t):\n",
        "        out=self.conv1(x)\n",
        "        t=self.time(t)\n",
        "        record=[out]\n",
        "        for down in self.down:\n",
        "            out=down(out,t)\n",
        "            print('out')\n",
        "            record.append(out)\n",
        "        out=self.middle(out,t)\n",
        "        for up in self.up:\n",
        "            if isinstance(up,UpSampleBlock):\n",
        "                out=up(out,t)\n",
        "            else:\n",
        "                out=torch.cat((out,record.pop()),dim=1)\n",
        "                out=up(out,t)\n",
        "        out=self.conv2(self.act(self.ins(out)))\n",
        "        return out"
      ],
      "metadata": {
        "id": "yFNJePSEGGQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearWarmupStepLRScheduler:\n",
        "    def __init__(self,optimizer,epochs,min_lr,init_lr,decay_rate,warmup_start_lr,warmup_steps):\n",
        "        self.optimizer=optimizer\n",
        "        self.epochs=epochs\n",
        "        self.decay_rate=decay_rate\n",
        "        self.init_lr=init_lr\n",
        "        self.min_lr=min_lr\n",
        "        self.warmup_start_lr=warmup_start_lr\n",
        "        self.warmup_steps=warmup_steps\n",
        "\n",
        "    def step(self,cur_epoch,cur_step):\n",
        "        if cur_epoch==0:\n",
        "            self.warmup_lr_schedule(\n",
        "                step=cur_step,\n",
        "                optimizer=self.optimizer,\n",
        "                max_step=self.warmup_steps,\n",
        "                init_lr=self.warmup_start_lr,\n",
        "                max_lr=self.init_lr,\n",
        "            )\n",
        "        else:\n",
        "            self.step_lr_schedule(\n",
        "                epoch=cur_epoch,\n",
        "                optimizer=self.optimizer,\n",
        "                init_lr=self.init_lr,\n",
        "                min_lr=self.min_lr,\n",
        "                decay_rate=self.decay_rate\n",
        "            )\n",
        "\n",
        "    def warmup_lr_schedule(self,optimizer, step, max_step, init_lr, max_lr):\n",
        "        \"\"\"Warmup the learning rate\"\"\"\n",
        "        lr = min(max_lr, init_lr + (max_lr - init_lr) * step / max(max_step, 1))\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group[\"lr\"] = lr\n",
        "\n",
        "    def step_lr_schedule(self,epoch,optimizer,init_lr,min_lr,decay_rate):\n",
        "        lr=max(min_lr,init_lr*(decay_rate**epoch))\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group[\"lr\"] = lr"
      ],
      "metadata": {
        "id": "5_g2JhCSGH6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from omegaconf import OmegaConf\n",
        "import logging\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from scipy import linalg\n",
        "from torchvision import datasets, transforms\n",
        "from PIL import Image\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    force=True  # 强制重新设置 logging 配置（Jupyter 已设置过一次）\n",
        ")\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "\n",
        "def padding(imgs,max_h=1024,max_w=1024,mode='constant'):\n",
        "    pad_img=[]\n",
        "    for i,img in enumerate(imgs):\n",
        "        try:\n",
        "            _, h, w = img.shape\n",
        "            pad_h = (max_h - h % max_h) % max_h\n",
        "            pad_w = (max_w - w % max_w) % max_w\n",
        "            pad_top = pad_h // 2\n",
        "            pad_bottom = pad_h - pad_top\n",
        "            pad_left = pad_w // 2\n",
        "            pad_right = pad_w - pad_left\n",
        "            padded = F.pad(img, (pad_left, pad_right, pad_top, pad_bottom), mode=mode)\n",
        "            mask=torch.ones_like(padded)\n",
        "            if pad_left>0:\n",
        "                for i in range(pad_left):\n",
        "                    alpha=i/pad_left\n",
        "                    padded[:,:,i]=alpha*padded[:,:,pad_left]\n",
        "            if pad_right>0:\n",
        "                for i in range(pad_right):\n",
        "                    alpha=i/pad_right\n",
        "                    padded[:,:,-(i+1)]=alpha*padded[:,:,-(pad_right+1)]\n",
        "            if pad_top>0:\n",
        "                for i in range(pad_top):\n",
        "                    alpha=i/pad_top\n",
        "                    padded[:,i,pad_left:-(pad_right+1)]=alpha*padded[:,pad_top,pad_left:-(pad_right+1)]\n",
        "                    padded[:,i,:pad_left]*=alpha*padded[:,pad_top,:pad_left]\n",
        "                    padded[:,i,-(pad_right+1):]*=alpha*padded[:,pad_top,-(pad_right+1):]\n",
        "            if pad_bottom>0:\n",
        "                for i in range(pad_bottom):\n",
        "                    alpha=i/pad_bottom\n",
        "                    padded[:,-(i+1),pad_left:-(pad_right+1)]=alpha*padded[:,-(pad_bottom+1),pad_left:-(pad_right+1)]\n",
        "                    padded[:,-(i+1),:pad_left]*=alpha*padded[:,-(pad_bottom+1),:pad_left]\n",
        "                    padded[:,-(i+1),-(pad_right+1):]*=alpha*padded[:,-(pad_bottom+1),-(pad_right+1):]\n",
        "            pad_img.append(padded)\n",
        "        except Exception as e:\n",
        "            print(f\"Error in padding img {i}: {e}\")\n",
        "    print(len(pad_img))\n",
        "    return torch.stack(pad_img)\n",
        "\n",
        "def custom_collate_fn(batch):\n",
        "    images=[x[0] for x in batch]\n",
        "    return padding(images)\n",
        "\n",
        "class DataSet(Dataset):\n",
        "    def __init__(self,data):\n",
        "        self.data=data\n",
        "    def __getitem__(self,index):\n",
        "        return self.data[index]\n",
        "    def __len__(self,):\n",
        "        return len(self,data)\n",
        "\n",
        "class Train:\n",
        "    def __init__(self,conf_path,img_path,model):\n",
        "        self.model_config=OmegaConf.load(conf_path)\n",
        "        self.optim=self.optimizer(model)\n",
        "        self.model=model\n",
        "        self.img_path=img_path\n",
        "    def get_optimizer_params(self,model,weight_decay,lr_scale=1):\n",
        "        p_wd,p_non_wd=[],[]\n",
        "        for n,p in model.named_parameters():\n",
        "            if p.ndim<2 or 'bias' in n:\n",
        "                p_non_wd.append(p)\n",
        "            else:\n",
        "                p_wd.append(p)\n",
        "        optim_params=[{\n",
        "            \"params\":p_wd,\"weight_decay\":weight_decay,\"lr_scale\":lr_scale\n",
        "        },{\n",
        "            \"params\":p_non_wd,\"weight_decay\":0,\"lr_scale\":lr_scale\n",
        "        }]\n",
        "        return optim_params\n",
        "\n",
        "    def optimizer(self,model):\n",
        "        optim_params=self.get_optimizer_params(model,self.model_config.run.weight_decay)\n",
        "        num_parameters=0\n",
        "        for p_group in optim_params:\n",
        "            for p in p_group['params']:\n",
        "                num_parameters+=p.data.nelement()\n",
        "        logging.info('number of trainable parameters: {}'.format(num_parameters))\n",
        "        optimizer=torch.optim.AdamW(optim_params,lr=self.model_config.run.init_lr,betas=(self.model_config.run.beta1,self.model_config.run.beta2))\n",
        "        return optimizer\n",
        "\n",
        "    def create_loader(self):\n",
        "        transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.5]*3,std=[0.5]*3)\n",
        "        ])\n",
        "        logging.info('start transform')\n",
        "        dataset=datasets.ImageFolder(self.img_path,transform=transform)\n",
        "        logging.info('finish transform')\n",
        "        bs=self.model_config.run.batch_size\n",
        "        num_workers=self.model_config.run.num_workers\n",
        "        loader=iter(DataLoader(dataset,batch_size=bs,collate_fn=custom_collate_fn,num_workers=num_workers,pin_memory=True))\n",
        "        return loader\n",
        "\n",
        "    def lr_scheduler(self,epochs):\n",
        "        min_lr=self.model_config.run.min_lr\n",
        "        init_lr=self.model_config.run.init_lr\n",
        "        decay_rate=self.model_config.run.lr_decay_rate\n",
        "        warmup_start_lr=self.model_config.run.warmup_lr\n",
        "        warmup_steps=self.model_config.run.warmup_steps\n",
        "        lr_sched = LinearWarmupStepLRScheduler(\n",
        "            optimizer=self.optimizer(self.model),\n",
        "            epochs=epochs,\n",
        "            min_lr=self.model_config.run.min_lr,\n",
        "            init_lr=self.model_config.run.init_lr,\n",
        "            decay_rate=self.model_config.run.lr_decay_rate,\n",
        "            warmup_start_lr=self.model_config.run.warmup_lr,\n",
        "            warmup_steps=self.model_config.run.warmup_steps,\n",
        "        )\n",
        "        return lr_sched\n",
        "\n",
        "    def train_epoch(self,epoch,iter_per_epoch,data_loader,lr_scheduler):\n",
        "        loss_list=[]\n",
        "        for i in tqdm(range(iter_per_epoch),desc='iter'):\n",
        "            samples=next(data_loader)\n",
        "            samples=samples\n",
        "            print(type(lr_scheduler))\n",
        "            lr_scheduler.step(epoch,i)\n",
        "            loss=self.denoise_score(samples,1,0.01)\n",
        "            loss.backward()\n",
        "            self.optim.step()\n",
        "            self.optim.zero_grad()\n",
        "            loss_value = loss.item() if hasattr(loss, \"item\") else float(loss)\n",
        "            loss_list.append(loss_value)  # 记录 loss\n",
        "            logging.info(\"cur_epoch:{0},cur_iter:{1},loss:{2}\".format(epoch,i,loss_value))\n",
        "        return loss_list\n",
        "    def train(self,epochs):\n",
        "        self.model.train()\n",
        "        all_losses = []\n",
        "        for epoch in tqdm(range(epochs),desc=\"epoch\"):\n",
        "            data_loader=self.create_loader()\n",
        "            logging.info(\"Start training\")\n",
        "            epoch_loss=self.train_epoch(epoch,len(data_loader),data_loader,self.lr_scheduler(epochs))\n",
        "            x=self.anneal_langevin_dynamics((1,3,1024,1024))\n",
        "            all_losses.extend(epoch_loss)\n",
        "            img = x.squeeze(0).permute(1,2,0).detach().cpu().numpy()\n",
        "            plt.imshow(img)\n",
        "            plt.show()\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        plt.plot(all_losses)\n",
        "        plt.title(\"Loss Curve\")\n",
        "        plt.xlabel(\"Iteration\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "    def denoise_score(self,x,init_sigma=1,end_sigma=0.01,L=10):\n",
        "\n",
        "        sigma_seq=torch.logspace(math.log10(init_sigma),math.log10(end_sigma),L)\n",
        "        bs=len(x)\n",
        "        idx=torch.randint(0,L,(bs,))\n",
        "        sigma=sigma_seq[idx].view(-1,1,1,1).to(x.device)\n",
        "        noise=sigma*torch.randn_like(x)\n",
        "        x_=x+noise\n",
        "        loss=0.5*((model(x_,sigma)+noise/sigma**2)**2).view(bs,-1).sum(dim=-1).mean()*sigma.squeeze()**2\n",
        "        return loss.mean()\n",
        "    #\n",
        "    def get_inception_score(self,dataloader,inception_model,splits):\n",
        "        inception_model.eval()\n",
        "        preds=[]\n",
        "        for batch in dataloader:\n",
        "            logits=inception_model(batch)\n",
        "            p_yx=F.softmax(logits,dim=-1)\n",
        "            preds.append(p_yx.cpu().numpy())\n",
        "        preds=np.concatenate(preds,axis=0)\n",
        "        N=preds.shape[0]\n",
        "        scores=[]\n",
        "        for i in range(splits):\n",
        "            part=preds[(i*preds.shape[0]//splits):((i+1)*preds.shape[0]//splits),:]\n",
        "            kl=part*(np.log(part)-np.log(np.expand_dims(np.mean(part,dim=0),0)))\n",
        "            kl=np.mean(np.sum(kl,1))\n",
        "            score.append(np.exp(kl))\n",
        "        return np.mean(score),np.std(score)\n",
        "\n",
        "    def get_fid(self,inception_model,real_img,generate_img):\n",
        "        real_f=inception_model(real_img)\n",
        "        generate_f=inception_model(generate_img)\n",
        "        mu1,sigma1=np.mean(real_f,axis=0),np.cov(real_f,rowvar=False)\n",
        "        mu2,sigma2=np.mean(generate_f,axis=0),np.cov(generate_f,rowvar=False)\n",
        "        diff=mu1-mu2\n",
        "        covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n",
        "        if np.iscomplexobj(covmean):\n",
        "            covmean=covmean.real\n",
        "        fid=diff.dot(diff)+np.trace(sigma1+sigma2-2*covmean)\n",
        "        return fid\n",
        "\n",
        "    def anneal_langevin_dynamics(self,shape,low=0,high=1,init_sigma=1,end_sigma=0.01,L=10,T=1,eps=2e-5):\n",
        "        x_t=(high-low)*torch.rand(shape)+low\n",
        "        sigma_seq = torch.logspace(math.log10(1), math.log10(0.01), 10)\n",
        "\n",
        "        for i in range(L):\n",
        "            sigma=sigma_seq[i]\n",
        "            alpha=eps*(sigma/end_sigma)**2\n",
        "            for t in range(T):\n",
        "                z = torch.randn_like(x_t)\n",
        "                # noise = sigma * torch.randn_like(x_t)\n",
        "                # x_in = x_t + noise\n",
        "                score = self.model(x_in,torch.tensor(sigma).view(1,1,1,1))  # 如果模型是 noise-conditional\n",
        "                x_t = x_t + alpha * score + torch.sqrt(alpha) * z\n",
        "        return x_t\n",
        "\n",
        "    def get_max_hw(self):\n",
        "        hm, wm = float('-inf'), float('-inf')\n",
        "        root = self.img_path  # dataset 根目录\n",
        "        for class_name in os.listdir(root):\n",
        "            class_path = os.path.join(root, class_name)\n",
        "            if not os.path.isdir(class_path):\n",
        "                continue\n",
        "            for fname in os.listdir(class_path):\n",
        "                fpath = os.path.join(class_path, fname)\n",
        "                try:\n",
        "                    with Image.open(fpath) as img:\n",
        "                        w, h = img.size  # 注意顺序：w,h\n",
        "                        hm = max(hm, h)\n",
        "                        wm = max(wm, w)\n",
        "                except Exception as e:\n",
        "                    print(f\"跳过无法识别的文件: {fpath}\")\n",
        "\n",
        "        print(\"最大高:\", hm)\n",
        "        print(\"最大宽:\", wm)\n",
        "\n",
        "    def save_checkpoint(self):\n",
        "        pass"
      ],
      "metadata": {
        "id": "ZiVc8loPGOH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Unet(3)\n",
        "conf_path='/content/drive/MyDrive/config.yaml'\n",
        "img_path='/content/drive/MyDrive/filter/'\n",
        "train=Train(conf_path,img_path,model)\n",
        "train.train(50)"
      ],
      "metadata": {
        "id": "87OtatRvGWRI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}