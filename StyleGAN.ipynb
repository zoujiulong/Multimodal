{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "mount_file_id": "1z9KbO5gQ-4z1Dsvnt62i-gjP1IZR6uBP",
      "authorship_tag": "ABX9TyMJQXvt0+ist8pBw0f6mlQr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zoujiulong/Multimodal/blob/main/StyleGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nMqpW0YPKDtm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import logging\n",
        "from torchvision import datasets,transforms\n",
        "from torch.utils.data import DataLoader,Subset\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import make_grid\n",
        "import math\n",
        "\n",
        "def custom_collate_fn(batch):\n",
        "    images=[x[0] for x in batch]\n",
        "    return torch.stack(images)\n",
        "\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    force=True  # 强制重新设置 logging 配置（Jupyter 已设置过一次）\n",
        ")\n",
        "\n",
        "class PixelNorm(nn.Module):\n",
        "  def __init__(self,eps=1e-5):\n",
        "    super().__init__()\n",
        "    self.eps=eps\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x shape: (batch_size, channels, height, width)\n",
        "    # 计算每个像素向量的均方根（RMS）\n",
        "    rms = torch.sqrt(torch.mean(x ** 2, dim=1, keepdim=True) + self.eps)\n",
        "    return x / rms\n",
        "\n",
        "class GenLayer(nn.Module):\n",
        "  def __init__(self,in_ch,resolution):\n",
        "    super().__init__()\n",
        "    self.up=nn.ConvTranspose2d(in_ch,in_ch//2,kernel_size=4,stride=2,padding=1)\n",
        "    self.act1=nn.LeakyReLU(inplace=False)\n",
        "    self.conv1=nn.Conv2d(in_ch//2,in_ch//2,kernel_size=3,padding=1)\n",
        "    self.act2=nn.LeakyReLU(inplace=False)\n",
        "    self.w1=nn.Parameter(torch.randn(in_ch//2))\n",
        "    self.noise1=torch.randn([resolution,resolution])\n",
        "    self.adaIn1=nn.InstanceNorm2d(in_ch//2,affine=False)\n",
        "    self.conv2=nn.Conv2d(in_ch//2,in_ch//2,kernel_size=3,padding=1)\n",
        "    self.act3=nn.LeakyReLU(inplace=False)\n",
        "    self.w2=nn.Parameter(torch.randn(in_ch//2))\n",
        "    self.noise2=torch.randn([resolution,resolution])\n",
        "    self.adaIn2=nn.InstanceNorm2d(in_ch//2,affine=False)\n",
        "\n",
        "  def forward(self,x,gamma,beta):\n",
        "    x=self.act2(self.conv1(self.act1(self.up(x))))\n",
        "    print((self.w1[:,None,None]*self.noise1).shape)\n",
        "    print(x.shape)\n",
        "    x=x+self.w1[:,None,None]*self.noise1\n",
        "    x=gamma[0][:,None,None]*self.adaIn1(x)+beta[0][:,None,None]\n",
        "    x=self.act3(self.conv2(x))\n",
        "    x=x+self.w2[:,None,None]*self.noise2\n",
        "    x=gamma[1][:,None,None]*self.adaIn2(x)+beta[1][:,None,None]\n",
        "    return x\n",
        "\n",
        "class StyleGen(nn.Module):\n",
        "  def __init__(self,resolution=4,out_ch=3,dim=512,map_num=8,syn_num=9):\n",
        "    super().__init__()\n",
        "    map=[]\n",
        "    for _ in range(map_num):\n",
        "      map.append(nn.Sequential(\n",
        "          nn.Linear(dim,dim),\n",
        "          nn.LeakyReLU()\n",
        "      ))\n",
        "    self.map=nn.ModuleList(map)\n",
        "    # self.normalize=PixelNorm()\n",
        "    self.adaIn1=nn.InstanceNorm2d(dim,affine=False)\n",
        "    self.w1=nn.Parameter(torch.randn(dim))\n",
        "    self.noise1=torch.randn([1,resolution,resolution])\n",
        "    self.In=nn.Conv2d(dim,dim,kernel_size=3,padding=1)\n",
        "    self.act1=nn.LeakyReLU(inplace=False)\n",
        "    self.adaIn2=nn.InstanceNorm2d(dim,affine=False)\n",
        "    self.w2=nn.Parameter(torch.randn(dim))\n",
        "    self.noise2=torch.randn([1,resolution,resolution])\n",
        "    layers=[]\n",
        "    affine=[]\n",
        "    d=dim\n",
        "    affine.append(nn.Linear(d,2*dim))\n",
        "    affine.append(nn.Linear(d,2*dim))\n",
        "    for _ in range(syn_num-1):\n",
        "      resolution*=2\n",
        "      layers.append(GenLayer(dim,resolution))\n",
        "      dim//=2\n",
        "      affine.append(nn.Linear(d,2*dim))\n",
        "      affine.append(nn.Linear(d,2*dim))\n",
        "    affine.append(nn.Linear(d,2*dim))\n",
        "    affine.append(nn.Linear(d,2*out_ch))\n",
        "    self.affine=nn.ModuleList(affine)\n",
        "    self.layers=nn.ModuleList(layers)\n",
        "    self.adaIn3=nn.InstanceNorm2d(dim,affine=False)\n",
        "    self.w3=nn.Parameter(torch.randn(dim))\n",
        "    self.noise3=torch.randn([1,resolution,resolution])\n",
        "    self.out=nn.Conv2d(dim,out_ch,kernel_size=1)\n",
        "    self.act2=nn.LeakyReLU(inplace=False)\n",
        "    self.adaIn4=nn.InstanceNorm2d(out_ch,affine=False)\n",
        "    self.w4=nn.Parameter(torch.randn(out_ch))\n",
        "    self.noise4=torch.randn([1,resolution,resolution])\n",
        "\n",
        "  def z_sample(self,dim=512):\n",
        "    z=torch.randn(dim)\n",
        "    z=F.normalize(z,dim=-1,p=2)\n",
        "    return z\n",
        "\n",
        "  def forward(self,x):\n",
        "    z=self.z_sample()\n",
        "    for fc in self.map:\n",
        "      z=fc(z)\n",
        "    x=x+self.w1[:,None,None]*self.noise1\n",
        "    gamma1,beta1=self.affine[0](z).chunk(2)\n",
        "    x=gamma1[:,None,None]*self.adaIn1(x)+beta1[:,None,None]\n",
        "    x=self.act1(self.In(x))+self.w2[:,None,None]*self.noise2\n",
        "    gamma2,beta2=self.affine[1](z).chunk(2)\n",
        "    x=gamma2[:,None,None]*self.adaIn2(x)+beta2[:,None,None]\n",
        "    for i,layer in enumerate(self.layers):\n",
        "      gamma5,beta5=self.affine[(i+1)*2](z).chunk(2)\n",
        "      gamma6,beta6=self.affine[(i+1)*2+1](z).chunk(2)\n",
        "      x=layer(x,[gamma5,gamma6],[beta5,beta6])\n",
        "    x=x+self.w3[:,None,None]*self.noise3\n",
        "    gamma3,beta3=self.affine[-2](z).chunk(2)\n",
        "    x=gamma3[:,None,None]*self.adaIn3(x)+beta3[:,None,None]\n",
        "    x=self.act2(self.out(x))+self.w4[:,None,None]*self.noise4\n",
        "    gamma4,beta4=self.affine[-1](z).chunk(2)\n",
        "    x=gamma4[:,None,None]*self.adaIn4(x)+beta4[:,None,None]\n",
        "    return x\n",
        "\n",
        "class DisLayer(nn.Module):\n",
        "  def __init__(self,in_ch,mul):\n",
        "    super().__init__()\n",
        "    self.conv1=nn.Conv2d(in_ch,in_ch,kernel_size=3,padding=1)\n",
        "    self.act1=nn.LeakyReLU(inplace=False)\n",
        "    self.conv2=nn.Conv2d(in_ch,in_ch,kernel_size=3,padding=1)\n",
        "    self.act2=nn.LeakyReLU(inplace=False)\n",
        "    self.down=nn.Conv2d(in_ch,mul*in_ch,kernel_size=4,stride=2,padding=1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=self.act1(self.conv1(x))\n",
        "    x=self.act2(self.conv2(x))\n",
        "    x=self.down(x)\n",
        "    return x\n",
        "\n",
        "class Disciminator(nn.Module):\n",
        "  def __init__(self,resolution=4,img_ch=3,in_ch=64,dis_num=8,ch_mul=(2,2,2,1)):\n",
        "    super().__init__()\n",
        "    self.conv1=nn.Conv2d(img_ch,in_ch,kernel_size=3,padding=1)\n",
        "    self.act1=nn.LeakyReLU(inplace=False)\n",
        "    layers=[]\n",
        "    l=len(ch_mul)\n",
        "    for i in range(dis_num):\n",
        "      layers.append(DisLayer(in_ch,ch_mul[min(i,l-1)]))\n",
        "      in_ch*=ch_mul[min(i,l-1)]\n",
        "    self.layers=nn.ModuleList(layers)\n",
        "    self.pool=nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.dense=nn.Linear(in_ch,1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=self.act1(self.conv1(x))\n",
        "    for layer in self.layers:\n",
        "      x=layer(x)\n",
        "      print(x.shape)\n",
        "    x=self.pool(x)\n",
        "    x=torch.flatten(x,1)\n",
        "    print(x.shape)\n",
        "    pred=self.dense(x)\n",
        "    return pred\n",
        "\n",
        "class StyleGAN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.generator=StyleGen()\n",
        "    self.discriminator=Disciminator()\n",
        "    self.g_optim=optim.Adam(self.generator.parameters())\n",
        "    self.d_optim=optim.Adam(self.discriminator.parameters())\n",
        "    self.const_input=nn.Parameter(torch.randn(1,512,4,4))\n",
        "    self.fixed_noise=torch.randn(1,512,4,4)\n",
        "  def create_loader(self,bs,dataset='FFHQ'):\n",
        "    if dataset=='mnist':\n",
        "      transform=transforms.Compose([\n",
        "          transforms.ToTensor(),\n",
        "      ])\n",
        "      train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "      small_dataset = Subset(train_dataset, range(1024))\n",
        "\n",
        "      loader = DataLoader(small_dataset, batch_size=bs, shuffle=True,collate_fn=custom_collate_fn)\n",
        "\n",
        "      # test_dataset  = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "    elif dataset=='FFHQ':\n",
        "      transform=transforms.Compose([\n",
        "          transforms.ToTensor(),\n",
        "      ])\n",
        "      dataset=datasets.ImageFolder('/content/drive/MyDrive/FFHQ',transform=transform)\n",
        "      loader = DataLoader(dataset, batch_size=bs, shuffle=True,collate_fn=custom_collate_fn)\n",
        "\n",
        "    else:\n",
        "      transform=transforms.Compose([\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Resize(280),\n",
        "          transforms.CenterCrop(256),\n",
        "      ])\n",
        "      logging.info('start transform')\n",
        "      dataset=datasets.ImageFolder(self.img_path,transform=transform)\n",
        "      logging.info('finish transform')\n",
        "      bs=self.model_config.run.batch_size\n",
        "      # num_workers=self.model_config.run.num_workers\n",
        "      loader=iter(DataLoader(dataset,batch_size=bs,collate_fn=custom_collate_fn,num_workers=1,pin_memory=True))\n",
        "    return loader\n",
        "\n",
        "  def train(self,bs=64,epochs=20):\n",
        "    loss_d_l,loss_g_l=[],[]\n",
        "    loader=self.create_loader(bs)\n",
        "    torch.autograd.set_detect_anomaly(True)\n",
        "    self.discriminator.train()\n",
        "    self.generator.train()\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "      for data in tqdm(loader):\n",
        "        noise=self.const_input.repeat(bs,1,1,1)\n",
        "        g=self.generator(noise)\n",
        "        print('g shape',g.shape)\n",
        "        pred_g= self.discriminator(g.detach())\n",
        "        pred_x= self.discriminator(data)\n",
        "        real_labels = torch.ones_like(pred_x)\n",
        "        fake_labels = torch.zeros_like(pred_g)\n",
        "        loss_d=criterion(pred_x, real_labels) + criterion(pred_g, fake_labels)\n",
        "        self.d_optim.zero_grad()\n",
        "        loss_d.backward()\n",
        "        self.d_optim.step()\n",
        "        loss_d_l.append(loss_d.item())\n",
        "        logging.info(\"cur_epoch:{0},d_loss:{1}\".format(epoch,loss_d.item()))\n",
        "        print('==========generator=============')\n",
        "        g=self.generator(noise)\n",
        "        pred_g=self.discriminator(g)\n",
        "        loss_g=criterion(pred_g,real_labels)\n",
        "        self.g_optim.zero_grad()\n",
        "        loss_g.backward()\n",
        "        self.g_optim.step()\n",
        "        logging.info(\"cur_epoch:{0},g_loss:{1}\".format(epoch,loss_g.item()))\n",
        "        loss_g_l.append(loss_g.item())\n",
        "      with torch.no_grad():\n",
        "        noise = self.fixed_noise.repeat(bs,1,1,1)\n",
        "        samples = self.generator(noise)\n",
        "        samples=torch.clip(samples,0,1)\n",
        "        grid=make_grid(samples,nrow=int(math.sqrt(bs)))\n",
        "        grid = grid.permute(1, 2, 0).cpu().numpy()\n",
        "        # 显示\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.imshow(grid)\n",
        "        plt.axis('off')  # 不显示坐标轴\n",
        "        plt.show()\n",
        "\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.plot(loss_d_l)\n",
        "    plt.title(\"D Loss Curve\")\n",
        "    plt.xlabel(\"Iteration\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.grid(True)\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.plot(loss_g_l)\n",
        "    plt.title(\"G Loss Curve\")\n",
        "    plt.xlabel(\"Iteration\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=StyleGAN()\n",
        "model.train(16)"
      ],
      "metadata": {
        "id": "oH4OMToDVJ3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cYnv1o18KO2K"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}