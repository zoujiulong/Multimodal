{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9B/D+xaSJhzwxJ4Dks/L/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zoujiulong/Multimodal/blob/main/DDPM_DDIM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0eqhOz4D4Y-"
      },
      "outputs": [],
      "source": [
        "!pip install -q omegaconf torchvision tqdm matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# class TimeEmedding(nn.Module):\n",
        "#     def __init__(self,in_channel):\n",
        "#         super().__init__()\n",
        "#         self.in_channel=in_channel\n",
        "#         self.proj1=nn.Linear(in_channel//4,in_channel)\n",
        "#         self.act1=nn.ELU()\n",
        "#         self.proj2=nn.Linear(in_channel,in_channel)\n",
        "#     def forward(self,t):\n",
        "#         print('t',t.shape)\n",
        "#         # t_emb=torch.empty((*t.shape[:-1],self.in_channel//4))\n",
        "#         print('t_emb',t_emb.shape)\n",
        "#         emb=math.log(10000)/(self.in_channel//8)\n",
        "#         emb=t[:,None]*torch.exp(torch.arange(self.in_channel//8)*-emb)\n",
        "#         print('emb',emb.shape)\n",
        "#         t_emb[:,:,:,::2]=emb.sin()\n",
        "#         t_emb[:,:,:,1::2]=emb.cos()\n",
        "#         t_emb=self.proj1(t_emb)\n",
        "#         t_emb=self.act1(t_emb)\n",
        "#         t_emb=self.proj2(t_emb)\n",
        "#         return t_emb\n",
        "class Swish(nn.Module):\n",
        "    \"\"\"\n",
        "    ### Swish activation function\n",
        "\n",
        "    $$x \\cdot \\sigma(x)$$\n",
        "    \"\"\"\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * torch.sigmoid(x)\n",
        "class TimeEmbedding(nn.Module):\n",
        "    \"\"\"\n",
        "    ### Embeddings for $t$\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_channels: int):\n",
        "        \"\"\"\n",
        "        * `n_channels` is the number of dimensions in the embedding\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.n_channels = n_channels\n",
        "        # First linear layer\n",
        "        self.lin1 = nn.Linear(self.n_channels // 4, self.n_channels)\n",
        "        # Activation\n",
        "        self.act = Swish()\n",
        "        # Second linear layer\n",
        "        self.lin2 = nn.Linear(self.n_channels, self.n_channels)\n",
        "\n",
        "    def forward(self, t: torch.Tensor):\n",
        "        # Create sinusoidal position embeddings\n",
        "        # [same as those from the transformer](../../transformers/positional_encoding.html)\n",
        "        #\n",
        "        # \\begin{align}\n",
        "        # PE^{(1)}_{t,i} &= sin\\Bigg(\\frac{t}{10000^{\\frac{i}{d - 1}}}\\Bigg) \\\\\n",
        "        # PE^{(2)}_{t,i} &= cos\\Bigg(\\frac{t}{10000^{\\frac{i}{d - 1}}}\\Bigg)\n",
        "        # \\end{align}\n",
        "        #\n",
        "        # where $d$ is `half_dim`\n",
        "        half_dim = self.n_channels // 8\n",
        "        emb = math.log(10_000) / (half_dim - 1)\n",
        "        emb = torch.exp(torch.arange(half_dim, device=t.device) * -emb)\n",
        "        emb = t[:, None] * emb[None, :]\n",
        "        emb = torch.cat((emb.sin(), emb.cos()), dim=1)\n",
        "\n",
        "        # Transform with the MLP\n",
        "        emb = self.act(self.lin1(emb))\n",
        "        emb = self.lin2(emb)\n",
        "\n",
        "        #\n",
        "        return emb\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self,head_num,ch,p=0.1):\n",
        "        super().__init__()\n",
        "        self.head_num=head_num\n",
        "        self.head_dim=ch//head_num\n",
        "        self.qkv=nn.Linear(ch,3*ch)\n",
        "        self.softmax=nn.Softmax()\n",
        "        self.drop1=nn.Dropout(p)\n",
        "        self.linear=nn.Linear(ch,ch)\n",
        "        self.drop2=nn.Dropout(p)\n",
        "    def forward(self,x):\n",
        "        bs,ch,h,w=x.shape\n",
        "        out=x.view(bs,ch,-1).permute(0,2,1)\n",
        "        out=self.qkv(out).view(bs,-1,self.head_num,3*self.head_dim).permute(0,2,1,3)\n",
        "        q,k,v=torch.chunk(out,3,dim=-1)\n",
        "        k=torch.transpose(k,-2,-1)\n",
        "        inter=(q@k)/(self.head_dim)**0.5\n",
        "        inter=self.drop1(self.softmax(inter))\n",
        "        o=inter@v\n",
        "        o=o.permute(0,2,1,3).contiguous()\n",
        "        o=o.view(bs,h*w,-1)\n",
        "        o=self.drop2(self.linear(o))\n",
        "        o=o.permute(0,2,1).view(bs,-1,h,w)+x\n",
        "        return o\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self,in_channel,out_channel,time_channel,n_groups=32,p=0.1):\n",
        "        super().__init__()\n",
        "        self.in_ch=in_channel\n",
        "        # self.ins1=nn.InstanceNorm2d(in_channel)\n",
        "        self.ins1=nn.GroupNorm(n_groups, in_channel)\n",
        "        # self.act1=nn.ELU()\n",
        "        self.act1=Swish()\n",
        "        self.conv1=nn.Conv2d(in_channel,out_channel,kernel_size=(3,3),padding=1)\n",
        "        # self.ins2=nn.InstanceNorm2d(in_channel)\n",
        "        self.ins2=nn.GroupNorm(n_groups, out_channel)\n",
        "        self.act2=Swish()\n",
        "        self.conv2=nn.Conv2d(out_channel,out_channel,kernel_size=(3,3),padding=1)\n",
        "        if in_channel!=out_channel:\n",
        "            self.residual=nn.Conv2d(in_channel,out_channel,kernel_size=(1,1))\n",
        "        else:\n",
        "            self.residual=nn.Identity()\n",
        "        self.time_emb = nn.Linear(time_channel, out_channel)\n",
        "        self.time_act = Swish()\n",
        "        self.dropout = nn.Dropout(p)\n",
        "    def forward(self,img,t):\n",
        "        out=self.conv1(self.act1(self.ins1(img)))\n",
        "        print('out',out.shape)\n",
        "        # out+=self.time_emb(self.time_act(t)).permute(0,3,1,2)\n",
        "        if t is not None:\n",
        "          out+=self.time_emb(self.time_act(t))[:, :, None, None]\n",
        "        out=self.conv2(self.dropout(self.act2(self.ins2(out))))\n",
        "        out+=self.residual(img)\n",
        "        return out\n",
        "\n",
        "class DownBlock(nn.Module):\n",
        "    def __init__(self,in_channel,out_channel,time_channel,head_num,has_attention=False):\n",
        "        super().__init__()\n",
        "        self.residual=ResidualBlock(in_channel,out_channel,time_channel)\n",
        "        if has_attention:\n",
        "            self.attention=Attention(head_num,out_channel)\n",
        "        else:\n",
        "            self.attention=nn.Identity()\n",
        "    def forward(self,img,t):\n",
        "        out=self.residual(img,t)\n",
        "        out=self.attention(out)\n",
        "        return out\n",
        "\n",
        "class MiddleBlock(nn.Module):\n",
        "    def __init__(self,in_channel,out_channel,time_channel,head_num):\n",
        "        super().__init__()\n",
        "        self.residual1=ResidualBlock(in_channel,out_channel,time_channel)\n",
        "        self.attention=Attention(head_num,out_channel)\n",
        "        self.residual2=ResidualBlock(out_channel,out_channel,time_channel)\n",
        "    def forward(self,img,t):\n",
        "        out=self.residual1(img,t)\n",
        "        out=self.attention(out)\n",
        "        print('attention')\n",
        "        out=self.residual2(out,t)\n",
        "        return out\n",
        "\n",
        "class UpBlock(nn.Module):\n",
        "    def __init__(self,in_channel,out_channel,time_channel,head_num,has_attention=False):\n",
        "        super().__init__()\n",
        "        self.residual=ResidualBlock(in_channel+out_channel,out_channel,time_channel)\n",
        "        if has_attention:\n",
        "            self.attention=Attention(head_num,out_channel)\n",
        "        else:\n",
        "            self.attention=nn.Identity()\n",
        "    def forward(self,img,t):\n",
        "        out=self.residual(img,t)\n",
        "        out=self.attention(out)\n",
        "        return out\n",
        "\n",
        "class DownSampleBlock(nn.Module):\n",
        "    def __init__(self,in_channel):\n",
        "        super().__init__()\n",
        "        self.conv=nn.Conv2d(in_channel,in_channel,kernel_size=(3,3),stride=(2,2),padding=(1,1))\n",
        "    def forward(self,img,t):\n",
        "        _=t\n",
        "        return self.conv(img)\n",
        "\n",
        "class UpSampleBlock(nn.Module):\n",
        "    def __init__(self,in_channel):\n",
        "        super().__init__()\n",
        "        self.conv=nn.ConvTranspose2d(in_channel,in_channel,kernel_size=(4,4),stride=(2,2),padding=(1,1))\n",
        "    def forward(self,img,t):\n",
        "        _=t\n",
        "        return self.conv(img)\n",
        "\n",
        "class Unet(nn.Module):\n",
        "    def __init__(self,layers,img_ch=1,in_channel=64,blocks=2,head_num=8):\n",
        "        super().__init__()\n",
        "        down=[]\n",
        "        coe=(1,2,2,4)\n",
        "        self.conv1=nn.Conv2d(img_ch,in_channel,kernel_size=(3,3),padding=(1,1))\n",
        "        self.time=TimeEmbedding(in_channel*4)\n",
        "        n_channel=in_channel\n",
        "        for i in range(layers):\n",
        "            out_ch=coe[i]*in_channel\n",
        "            # print(out_ch)\n",
        "            # print(in_channel)\n",
        "            for _ in range(blocks):\n",
        "                down.append(DownBlock(in_channel,out_ch,n_channel*4,head_num))\n",
        "                in_channel=out_ch\n",
        "            # print(in_channel)\n",
        "            # print(out_ch)\n",
        "            if i<layers-1:\n",
        "                down.append(DownSampleBlock(out_ch))\n",
        "        self.down=nn.ModuleList(down)\n",
        "        self.middle=MiddleBlock(out_ch,out_ch,n_channel*4,head_num)\n",
        "        up=[]\n",
        "        in_channel=out_ch\n",
        "        for i in range(layers):\n",
        "            out_ch=in_channel\n",
        "            for _ in range(blocks):\n",
        "                up.append(UpBlock(in_channel,out_ch,n_channel*4,head_num))\n",
        "            out_ch=in_channel//coe[layers-1-i]\n",
        "            up.append(UpBlock(in_channel,out_ch,n_channel*4,head_num))\n",
        "            in_channel=out_ch\n",
        "            if i<layers-1:\n",
        "                up.append(UpSampleBlock(in_channel))\n",
        "        self.up=nn.ModuleList(up)\n",
        "        # self.ins=nn.InstanceNorm2d(in_channel)\n",
        "        self.ins=nn.GroupNorm(8, n_channel)\n",
        "\n",
        "        # self.act=nn.ELU()\n",
        "        self.act=Swish()\n",
        "        self.conv2=nn.Conv2d(in_channel,img_ch,kernel_size=(3,3),padding=(1,1))\n",
        "    def forward(self,x,t):\n",
        "        out=self.conv1(x)\n",
        "        t=self.time(t)\n",
        "        record=[out]\n",
        "        for down in self.down:\n",
        "            out=down(out,t)\n",
        "            print('out')\n",
        "            record.append(out)\n",
        "        out=self.middle(out,t)\n",
        "        for up in self.up:\n",
        "            if isinstance(up,UpSampleBlock):\n",
        "                out=up(out,t)\n",
        "            else:\n",
        "                out=torch.cat((out,record.pop()),dim=1)\n",
        "                out=up(out,t)\n",
        "        out=self.conv2(self.act(self.ins(out)))\n",
        "        return out"
      ],
      "metadata": {
        "id": "EC88775mD9ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "from omegaconf import OmegaConf\n",
        "from torchvision import datasets, transforms\n",
        "import logging\n",
        "from torch.utils.data import DataLoader,Dataset,Subset\n",
        "\n",
        "def custom_collate_fn(batch):\n",
        "    images=[x[0] for x in batch]\n",
        "    return torch.stack(images)\n",
        "# def custom_collate_fn(batch):\n",
        "#     images=[x[0] for x in batch]\n",
        "#     return torch.stack(images)\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    force=True  # 强制重新设置 logging 配置（Jupyter 已设置过一次）\n",
        ")\n",
        "\n",
        "class DDPM(nn.Module):\n",
        "  def __init__(self,beta_s,beta_e,time_steps,conf_path,img_path):\n",
        "    self.model_config=OmegaConf.load(conf_path)\n",
        "    self.img_path=img_path\n",
        "    super().__init__()\n",
        "    self.predict_model=Unet(3)\n",
        "    self.time_steps=time_steps\n",
        "    beta=torch.linspace(beta_s,beta_e,time_steps).numpy()\n",
        "    # yes\n",
        "    alpha=1-beta\n",
        "    #\n",
        "    self.cum_prod_alpha=np.cumprod(alpha)\n",
        "    self.cum_prod_alpha_prev=np.append(1,alpha[:-1])\n",
        "    self.sqrt_cum_prod_alpha=torch.tensor(np.sqrt(self.cum_prod_alpha),dtype=torch.float32)\n",
        "    self.sqrt_one_cum_prod_alpha=torch.tensor(np.sqrt(1-self.cum_prod_alpha),dtype=torch.float32)\n",
        "    self.optim=torch.optim.Adam(self.predict_model.parameters(),lr=2e-4)\n",
        "    self.posterior_mean_coef1=torch.tensor(beta*np.sqrt(self.cum_prod_alpha_prev)/(1-self.cum_prod_alpha),dtype=torch.float32)\n",
        "    self.posterior_mean_coef2=torch.tensor((1-self.cum_prod_alpha_prev)*np.sqrt(alpha)/(1-self.cum_prod_alpha),dtype=torch.float32)\n",
        "    self.sqrt_recip_alphas_cumprod=torch.tensor(np.sqrt(1/self.cum_prod_alpha),dtype=torch.float32)\n",
        "    self.sqrt_recipm1_alphas_cumprod=torch.tensor(np.sqrt(1/self.cum_prod_alpha-1),dtype=torch.float32)\n",
        "    self.posterior_variance=torch.tensor(beta*(1-self.cum_prod_alpha_prev)/(1-self.cum_prod_alpha))\n",
        "    self.posterior_log_variance_clipped=torch.tensor(np.log(np.maximum(self.posterior_variance,1e-20)),dtype=torch.float32)\n",
        "  def p_sample(self,x,t):\n",
        "    b=x.shape[0]\n",
        "    noise=torch.randn_like(x)\n",
        "    model_mean,_,model_log_var=self.p_mean_variance(x,t,noise)\n",
        "    nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))\n",
        "    return model_mean + nonzero_mask * (0.5 * model_log_var).exp() * noise\n",
        "\n",
        "  def q_posterior(self, x_start, x_t, t):\n",
        "      posterior_mean = (\n",
        "              self.extract_into_tensor(self.posterior_mean_coef1, t, x_t.shape) * x_start +\n",
        "              self.extract_into_tensor(self.posterior_mean_coef2, t, x_t.shape) * x_t\n",
        "      )\n",
        "      posterior_variance = self.extract_into_tensor(self.posterior_variance, t, x_t.shape)\n",
        "      posterior_log_variance_clipped = self.extract_into_tensor(self.posterior_log_variance_clipped, t, x_t.shape)\n",
        "      return posterior_mean, posterior_variance, posterior_log_variance_clipped\n",
        "\n",
        "  def predict_start_from_noise(self, x_t, t, noise):\n",
        "      return (\n",
        "              self.extract_into_tensor(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t -\n",
        "              self.extract_into_tensor(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise\n",
        "      )\n",
        "\n",
        "  def p_mean_variance(self, x, t, clip_denoised: bool):\n",
        "      model_out = self.predict_model(x, t)\n",
        "      x_recon = self.predict_start_from_noise(x, t=t, noise=model_out)\n",
        "      model_mean, posterior_variance, posterior_log_variance = self.q_posterior(x_start=x_recon, x_t=x, t=t)\n",
        "      return model_mean, posterior_variance, posterior_log_variance\n",
        "\n",
        "  def extract_into_tensor(self,a, t, x_shape):\n",
        "    b, *_ = t.shape\n",
        "    out = a.gather(-1, t)\n",
        "    return out.reshape(b, *((1,) * (len(x_shape) - 1)))\n",
        "\n",
        "  def q_sample(self,x,t,noise):\n",
        "    return self.extract_into_tensor(self.sqrt_cum_prod_alpha,t,x.shape)*x+self.extract_into_tensor(self.sqrt_one_cum_prod_alpha,t,x.shape)*noise\n",
        "\n",
        "  def p_loss(self,x,t,noise):\n",
        "    x_noise=self.diffusion(x,t,noise)\n",
        "    pred=self.predict_model(x_noise,t)\n",
        "    loss=torch.nn.functional.mse_loss(pred,noise,reduction='none').mean()\n",
        "    return loss\n",
        "\n",
        "  def diffusion(self,x,t,noise):\n",
        "    bs=x.shape[0]\n",
        "    x_noise=self.q_sample(x,t,noise)\n",
        "    return x_noise\n",
        "\n",
        "  def create_loader(self,dataset='mnist'):\n",
        "    if dataset=='mnist':\n",
        "      transform=transforms.Compose([\n",
        "          transforms.ToTensor(),\n",
        "      ])\n",
        "      train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "      small_dataset = Subset(train_dataset, range(1024))\n",
        "\n",
        "      loader = DataLoader(small_dataset, batch_size=128, shuffle=True,collate_fn=custom_collate_fn)\n",
        "\n",
        "      # test_dataset  = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "    else:\n",
        "      transform=transforms.Compose([\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Resize(280),\n",
        "          transforms.CenterCrop(256),\n",
        "      ])\n",
        "      logging.info('start transform')\n",
        "      dataset=datasets.ImageFolder(self.img_path,transform=transform)\n",
        "      logging.info('finish transform')\n",
        "      bs=self.model_config.run.batch_size\n",
        "      # num_workers=self.model_config.run.num_workers\n",
        "      loader=iter(DataLoader(dataset,batch_size=bs,collate_fn=custom_collate_fn,num_workers=1,pin_memory=True))\n",
        "    return loader\n",
        "#  ddpm的采样\n",
        "  @torch.no_grad()\n",
        "  def sample_loop(self, shape):\n",
        "    img = torch.randn(shape)  # 确保到GPU上\n",
        "    for t in reversed(range(self.time_steps)):\n",
        "      t_batch = torch.full((img.shape[0],), t,dtype=torch.long)\n",
        "      img = self.p_sample(img, t_batch)\n",
        "    img = torch.clamp(img, 0, 1)\n",
        "    return img\n",
        "\n",
        "  def ddim_p_sample(self,x,t,interval,eta):\n",
        "    noise=torch.randn_like(x)\n",
        "    model_out=self.predict_model(x,t)\n",
        "    x_recon=self.predict_start_from_noise(x,t,model_out)\n",
        "    t_prev=torch.clamp(t-interval,min=0)\n",
        "    sigma=eta**2*self.posterior_variance\n",
        "    return self.extract_into_tensor(self.sqrt_cum_prod_alpha,t_prev,x.shape)*x_recon+self.extract_into_tensor(torch.sqrt((1-torch.from_numpy(self.cum_prod_alpha).float()-sigma.float())),t_prev,x.shape)*model_out+self.extract_into_tensor(torch.sqrt(sigma.float()),t_prev,x.shape)*noise\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def ddim_sample_loop(self, shape,interval,eta):\n",
        "    img = torch.randn(shape)  # 确保到GPU上\n",
        "    for t in reversed(range(0,self.time_steps,interval)):\n",
        "      t_batch = torch.full((img.shape[0],), t,dtype=torch.long)\n",
        "      img = self.ddim_p_sample(img, t_batch,interval,eta)\n",
        "    img = torch.clamp(img, 0, 1)\n",
        "    return img\n",
        "\n",
        "  def train(self,epochs,shape,interval,eta=0):\n",
        "    loss_list=[]\n",
        "    for epoch in tqdm(range(epochs),desc='epoch'):\n",
        "      loader=self.create_loader()\n",
        "      for x in tqdm(loader):\n",
        "        loss=self(x)\n",
        "        loss_value = loss.item() if hasattr(loss, \"item\") else float(loss)\n",
        "        logging.info(\"cur_epoch:{0},loss:{1}\".format(epoch,loss_value))\n",
        "        loss_list.append(loss_value)\n",
        "        self.optim.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optim.step()\n",
        "      img = self.ddim_sample_loop(shape,interval,eta)\n",
        "      grid=make_grid(img,nrow=shape[0])\n",
        "      grid = grid.permute(1, 2, 0).cpu().numpy()\n",
        "      # 显示\n",
        "      plt.figure(figsize=(12, 6))\n",
        "      plt.imshow(grid)\n",
        "      plt.axis('off')  # 不显示坐标轴\n",
        "      plt.show()\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.plot(loss_list)\n",
        "    plt.title(\"Loss Curve\")\n",
        "    plt.xlabel(\"Iteration\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "  def forward(self,x):\n",
        "    bs=x.shape[0]\n",
        "    t=torch.randint(0,self.time_steps,(bs,))\n",
        "    noise=torch.randn_like(x)\n",
        "    loss=self.p_loss(x,t,noise)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "HJj7MDVuD_05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_path='/content/drive/MyDrive/config.yaml'\n",
        "img_path='/content/drive/MyDrive/filter/'\n",
        "model=DDPM(1e-4,2e-2,100,conf_path,img_path)\n",
        "model.train(50,(16,1,28,28),20)"
      ],
      "metadata": {
        "id": "CRmt-RfSEDbt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}