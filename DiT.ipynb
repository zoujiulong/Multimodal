{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkDfv3f9XFAIh+nSUJZoiZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zoujiulong/Multimodal/blob/main/DiT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUyVwSCkEncc"
      },
      "outputs": [],
      "source": [
        "!pip install -q omegaconf torchvision tqdm matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# class TimeEmedding(nn.Module):\n",
        "#     def __init__(self,in_channel):\n",
        "#         super().__init__()\n",
        "#         self.in_channel=in_channel\n",
        "#         self.proj1=nn.Linear(in_channel//4,in_channel)\n",
        "#         self.act1=nn.ELU()\n",
        "#         self.proj2=nn.Linear(in_channel,in_channel)\n",
        "#     def forward(self,t):\n",
        "#         print('t',t.shape)\n",
        "#         # t_emb=torch.empty((*t.shape[:-1],self.in_channel//4))\n",
        "#         print('t_emb',t_emb.shape)\n",
        "#         emb=math.log(10000)/(self.in_channel//8)\n",
        "#         emb=t[:,None]*torch.exp(torch.arange(self.in_channel//8)*-emb)\n",
        "#         print('emb',emb.shape)\n",
        "#         t_emb[:,:,:,::2]=emb.sin()\n",
        "#         t_emb[:,:,:,1::2]=emb.cos()\n",
        "#         t_emb=self.proj1(t_emb)\n",
        "#         t_emb=self.act1(t_emb)\n",
        "#         t_emb=self.proj2(t_emb)\n",
        "#         return t_emb\n",
        "class Swish(nn.Module):\n",
        "    \"\"\"\n",
        "    ### Swish activation function\n",
        "\n",
        "    $$x \\cdot \\sigma(x)$$\n",
        "    \"\"\"\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * torch.sigmoid(x)\n",
        "class TimeEmbedding(nn.Module):\n",
        "    \"\"\"\n",
        "    ### Embeddings for $t$\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_channels: int):\n",
        "        \"\"\"\n",
        "        * `n_channels` is the number of dimensions in the embedding\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.n_channels = n_channels\n",
        "        # First linear layer\n",
        "        self.lin1 = nn.Linear(self.n_channels // 4, self.n_channels)\n",
        "        # Activation\n",
        "        self.act = Swish()\n",
        "        # Second linear layer\n",
        "        self.lin2 = nn.Linear(self.n_channels, self.n_channels)\n",
        "\n",
        "    def forward(self, t: torch.Tensor):\n",
        "        # Create sinusoidal position embeddings\n",
        "        # [same as those from the transformer](../../transformers/positional_encoding.html)\n",
        "        #\n",
        "        # \\begin{align}\n",
        "        # PE^{(1)}_{t,i} &= sin\\Bigg(\\frac{t}{10000^{\\frac{i}{d - 1}}}\\Bigg) \\\\\n",
        "        # PE^{(2)}_{t,i} &= cos\\Bigg(\\frac{t}{10000^{\\frac{i}{d - 1}}}\\Bigg)\n",
        "        # \\end{align}\n",
        "        #\n",
        "        # where $d$ is `half_dim`\n",
        "        half_dim = self.n_channels // 8\n",
        "        emb = math.log(10_000) / (half_dim - 1)\n",
        "        emb = torch.exp(torch.arange(half_dim, device=t.device) * -emb)\n",
        "        emb = t[:, None] * emb[None, :]\n",
        "        emb = torch.cat((emb.sin(), emb.cos()), dim=1)\n",
        "\n",
        "        # Transform with the MLP\n",
        "        emb = self.act(self.lin1(emb))\n",
        "        emb = self.lin2(emb)\n",
        "\n",
        "        #\n",
        "        return emb\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self,head_num,ch,p=0.1):\n",
        "        super().__init__()\n",
        "        self.head_num=head_num\n",
        "        self.head_dim=ch//head_num\n",
        "        self.qkv=nn.Linear(ch,3*ch)\n",
        "        self.softmax=nn.Softmax()\n",
        "        self.drop1=nn.Dropout(p)\n",
        "        self.linear=nn.Linear(ch,ch)\n",
        "        self.drop2=nn.Dropout(p)\n",
        "    def forward(self,x):\n",
        "        bs,ch,h,w=x.shape\n",
        "        out=x.view(bs,ch,-1).permute(0,2,1)\n",
        "        out=self.qkv(out).view(bs,-1,self.head_num,3*self.head_dim).permute(0,2,1,3)\n",
        "        q,k,v=torch.chunk(out,3,dim=-1)\n",
        "        k=torch.transpose(k,-2,-1)\n",
        "        inter=(q@k)/(self.head_dim)**0.5\n",
        "        inter=self.drop1(self.softmax(inter))\n",
        "        o=inter@v\n",
        "        o=o.permute(0,2,1,3).contiguous()\n",
        "        o=o.view(bs,h*w,-1)\n",
        "        o=self.drop2(self.linear(o))\n",
        "        o=o.permute(0,2,1).view(bs,-1,h,w)+x\n",
        "        return o\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self,in_channel,out_channel,time_channel,n_groups=32,p=0.1):\n",
        "        super().__init__()\n",
        "        self.in_ch=in_channel\n",
        "        # self.ins1=nn.InstanceNorm2d(in_channel)\n",
        "        self.ins1=nn.GroupNorm(n_groups, in_channel)\n",
        "        # self.act1=nn.ELU()\n",
        "        self.act1=Swish()\n",
        "        self.conv1=nn.Conv2d(in_channel,out_channel,kernel_size=(3,3),padding=1)\n",
        "        # self.ins2=nn.InstanceNorm2d(in_channel)\n",
        "        self.ins2=nn.GroupNorm(n_groups, out_channel)\n",
        "        self.act2=Swish()\n",
        "        self.conv2=nn.Conv2d(out_channel,out_channel,kernel_size=(3,3),padding=1)\n",
        "        if in_channel!=out_channel:\n",
        "            self.residual=nn.Conv2d(in_channel,out_channel,kernel_size=(1,1))\n",
        "        else:\n",
        "            self.residual=nn.Identity()\n",
        "        self.time_emb = nn.Linear(time_channel, out_channel)\n",
        "        self.time_act = Swish()\n",
        "        self.dropout = nn.Dropout(p)\n",
        "    def forward(self,img,t):\n",
        "        out=self.conv1(self.act1(self.ins1(img)))\n",
        "        print('out',out.shape)\n",
        "        # out+=self.time_emb(self.time_act(t)).permute(0,3,1,2)\n",
        "        if t is not None:\n",
        "          out+=self.time_emb(self.time_act(t))[:, :, None, None]\n",
        "        out=self.conv2(self.dropout(self.act2(self.ins2(out))))\n",
        "        out+=self.residual(img)\n",
        "        return out\n",
        "\n",
        "class DownBlock(nn.Module):\n",
        "    def __init__(self,in_channel,out_channel,time_channel,head_num,has_attention=False):\n",
        "        super().__init__()\n",
        "        self.residual=ResidualBlock(in_channel,out_channel,time_channel)\n",
        "        if has_attention:\n",
        "            self.attention=Attention(head_num,out_channel)\n",
        "        else:\n",
        "            self.attention=nn.Identity()\n",
        "    def forward(self,img,t):\n",
        "        out=self.residual(img,t)\n",
        "        out=self.attention(out)\n",
        "        return out\n",
        "\n",
        "class MiddleBlock(nn.Module):\n",
        "    def __init__(self,in_channel,out_channel,time_channel,head_num):\n",
        "        super().__init__()\n",
        "        self.residual1=ResidualBlock(in_channel,out_channel,time_channel)\n",
        "        self.attention=Attention(head_num,out_channel)\n",
        "        self.residual2=ResidualBlock(out_channel,out_channel,time_channel)\n",
        "    def forward(self,img,t):\n",
        "        out=self.residual1(img,t)\n",
        "        out=self.attention(out)\n",
        "        print('attention')\n",
        "        out=self.residual2(out,t)\n",
        "        return out\n",
        "\n",
        "class UpBlock(nn.Module):\n",
        "    def __init__(self,in_channel,out_channel,time_channel,head_num,has_attention=False):\n",
        "        super().__init__()\n",
        "        self.residual=ResidualBlock(in_channel+out_channel,out_channel,time_channel)\n",
        "        if has_attention:\n",
        "            self.attention=Attention(head_num,out_channel)\n",
        "        else:\n",
        "            self.attention=nn.Identity()\n",
        "    def forward(self,img,t):\n",
        "        out=self.residual(img,t)\n",
        "        out=self.attention(out)\n",
        "        return out\n",
        "\n",
        "class DownSampleBlock(nn.Module):\n",
        "    def __init__(self,in_channel):\n",
        "        super().__init__()\n",
        "        self.conv=nn.Conv2d(in_channel,in_channel,kernel_size=(3,3),stride=(2,2),padding=(1,1))\n",
        "    def forward(self,img,t):\n",
        "        _=t\n",
        "        return self.conv(img)\n",
        "\n",
        "class UpSampleBlock(nn.Module):\n",
        "    def __init__(self,in_channel):\n",
        "        super().__init__()\n",
        "        self.conv=nn.ConvTranspose2d(in_channel,in_channel,kernel_size=(4,4),stride=(2,2),padding=(1,1))\n",
        "    def forward(self,img,t):\n",
        "        _=t\n",
        "        return self.conv(img)\n",
        "\n",
        "class Unet(nn.Module):\n",
        "    def __init__(self,layers,img_ch=1,in_channel=64,blocks=2,head_num=8):\n",
        "        super().__init__()\n",
        "        down=[]\n",
        "        coe=(1,2,2,4)\n",
        "        self.conv1=nn.Conv2d(img_ch,in_channel,kernel_size=(3,3),padding=(1,1))\n",
        "        self.time=TimeEmbedding(in_channel*4)\n",
        "        n_channel=in_channel\n",
        "        for i in range(layers):\n",
        "            out_ch=coe[i]*in_channel\n",
        "            # print(out_ch)\n",
        "            # print(in_channel)\n",
        "            for _ in range(blocks):\n",
        "                down.append(DownBlock(in_channel,out_ch,n_channel*4,head_num))\n",
        "                in_channel=out_ch\n",
        "            # print(in_channel)\n",
        "            # print(out_ch)\n",
        "            if i<layers-1:\n",
        "                down.append(DownSampleBlock(out_ch))\n",
        "        self.down=nn.ModuleList(down)\n",
        "        self.middle=MiddleBlock(out_ch,out_ch,n_channel*4,head_num)\n",
        "        up=[]\n",
        "        in_channel=out_ch\n",
        "        for i in range(layers):\n",
        "            out_ch=in_channel\n",
        "            for _ in range(blocks):\n",
        "                up.append(UpBlock(in_channel,out_ch,n_channel*4,head_num))\n",
        "            out_ch=in_channel//coe[layers-1-i]\n",
        "            up.append(UpBlock(in_channel,out_ch,n_channel*4,head_num))\n",
        "            in_channel=out_ch\n",
        "            if i<layers-1:\n",
        "                up.append(UpSampleBlock(in_channel))\n",
        "        self.up=nn.ModuleList(up)\n",
        "        # self.ins=nn.InstanceNorm2d(in_channel)\n",
        "        self.ins=nn.GroupNorm(8, n_channel)\n",
        "\n",
        "        # self.act=nn.ELU()\n",
        "        self.act=Swish()\n",
        "        self.conv2=nn.Conv2d(in_channel,img_ch,kernel_size=(3,3),padding=(1,1))\n",
        "    def forward(self,x,t):\n",
        "        out=self.conv1(x)\n",
        "        t=self.time(t)\n",
        "        record=[out]\n",
        "        for down in self.down:\n",
        "            out=down(out,t)\n",
        "            print('out')\n",
        "            record.append(out)\n",
        "        out=self.middle(out,t)\n",
        "        for up in self.up:\n",
        "            if isinstance(up,UpSampleBlock):\n",
        "                out=up(out,t)\n",
        "            else:\n",
        "                out=torch.cat((out,record.pop()),dim=1)\n",
        "                out=up(out,t)\n",
        "        out=self.conv2(self.act(self.ins(out)))\n",
        "        return out"
      ],
      "metadata": {
        "id": "df9gsQFhEtDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import math\n",
        "import random\n",
        "\n",
        "class PatchEmbed(nn.Module):\n",
        "  def __init__(self,in_ch=4,embed_dim=768,patch_dim=2):\n",
        "    super().__init__()\n",
        "    self.embed_dim=embed_dim\n",
        "    self.proj=nn.Conv2d(in_ch,embed_dim,kernel_size=patch_dim,stride=patch_dim)\n",
        "  def forward(self,x):\n",
        "    b,c,h,w=x.shape\n",
        "    x=self.proj(x)\n",
        "    x=x.view(b,self.embed_dim,-1).permute(0,2,1)\n",
        "    return x\n",
        "\n",
        "class CondEmbedding(nn.Module):\n",
        "  def __init__(self,num_class,embed_dim):\n",
        "    super().__init__()\n",
        "    self.d=embed_dim//2\n",
        "    self.c=nn.Embedding(num_class,embed_dim)\n",
        "  def forward(self,t,label):\n",
        "    embed=torch.arange(self.d)\n",
        "    embed=torch.exp(-embed/(self.d-1)*math.log(10**4))\n",
        "    embed=t[:,None]*embed[None,:]\n",
        "    embed=torch.cat((embed.sin(),embed.cos()),dim=-1)\n",
        "    c=self.c(label)\n",
        "    cond_emb=torch.cat((embed[:,None,:],c[:,None,:]),dim=1)\n",
        "    return cond_emb\n",
        "\n",
        "class SpatialAttention(nn.Module):\n",
        "  def __init__(self,in_dim,heads,head_dim,types=''):\n",
        "    super().__init__()\n",
        "    self.norm1=nn.LayerNorm(in_dim)\n",
        "    inner_dim=head_dim*heads\n",
        "    self.types=types\n",
        "    self.heads=heads\n",
        "    self.q=nn.Linear(in_dim,inner_dim)\n",
        "    self.k=nn.Linear(in_dim,inner_dim)\n",
        "    self.v=nn.Linear(in_dim,inner_dim)\n",
        "    self.act=nn.Softmax(dim=-1)\n",
        "    self.drop1=nn.Dropout()\n",
        "    self.linear=nn.Linear(inner_dim,inner_dim)\n",
        "    self.drop2=nn.Dropout()\n",
        "    self.norm2=nn.LayerNorm(in_dim)\n",
        "    self.ffn=nn.Sequential(\n",
        "        nn.Linear(inner_dim,4*inner_dim),\n",
        "        nn.GELU(),\n",
        "        nn.Linear(4*inner_dim,inner_dim)\n",
        "    )\n",
        "    self.mlp1=nn.Sequential(\n",
        "        nn.Linear(2 * inner_dim, 3 * inner_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(3 * inner_dim, 3 * inner_dim),\n",
        "    )\n",
        "    self.mlp2=nn.Sequential(\n",
        "        nn.Linear(2 * inner_dim, 3 * inner_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(3 * inner_dim, 3 * inner_dim),\n",
        "    )\n",
        "\n",
        "  def forward(self,x,c):\n",
        "    b,n,embed=x.shape\n",
        "    alpha=None\n",
        "    if self.types=='ada':\n",
        "      gamma,beta,alpha=self.mlp1(c.view(b,-1)).view(b,3,-1).chunk(3,dim=1)\n",
        "      x=gamma*self.norm1(x)+beta\n",
        "    else:\n",
        "      x=self.norm1(x)\n",
        "    q=self.q(x).view(b,n,self.heads,-1).permute(0,2,1,3)\n",
        "    if self.types=='crossattn':\n",
        "      k=self.k(c).view(b,-1,self.heads,q.shape[-1]).permute(0,2,1,3)\n",
        "      v=self.v(c).view(b,-1,self.heads,q.shape[-1]).permute(0,2,1,3)\n",
        "    else:\n",
        "      k=self.k(x).view(b,-1,self.heads,q.shape[-1]).permute(0,2,1,3)\n",
        "      v=self.v(x).view(b,-1,self.heads,q.shape[-1]).permute(0,2,1,3)\n",
        "    inter=self.drop1(self.act(q@k.transpose(-1,-2)/math.sqrt(q.shape[-1])))\n",
        "    o=(inter@v).permute(0,2,1,3).flatten(2)\n",
        "    o=self.drop2(self.linear(o))\n",
        "    if self.types=='ada':\n",
        "      o=self.norm2(alpha*o+x)\n",
        "      gamma,beta,alpha=self.mlp2(c.view(b,-1)).view(b,3,-1).chunk(3,dim=1)\n",
        "      o=gamma*o+beta\n",
        "      o=o+alpha*self.ffn(o)\n",
        "    else:\n",
        "      o=self.norm2(o+x)\n",
        "      o=o+self.ffn(o)\n",
        "    return o\n",
        "\n",
        "class DiT(nn.Module):\n",
        "  def __init__(self,beta_s,beta_e,time_steps,num_class,in_ch=4,layers=12,embed_dim=768,head_nums=12,patch_dim=2,types='',img_size=224):\n",
        "    super().__init__()\n",
        "    self.cond_emb=CondEmbedding(num_class,embed_dim)\n",
        "    self.num_class=num_class\n",
        "    self.types=types\n",
        "    self.blocks=nn.ModuleList()\n",
        "    self.mlp=nn.Sequential(\n",
        "            nn.Linear(2 * embed_dim, 3 * embed_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(3 * embed_dim, 3 * embed_dim),\n",
        "        )\n",
        "    self.patch=PatchEmbed(in_ch,embed_dim,patch_dim)\n",
        "    for i in range(layers):\n",
        "      self.blocks.append(SpatialAttention(embed_dim,head_nums,embed_dim//head_nums,self.types))\n",
        "    self.norm=nn.LayerNorm(embed_dim)\n",
        "    self.patch_dim=patch_dim\n",
        "    self.linear = nn.Linear(embed_dim, patch_dim * patch_dim * 2 * in_ch)\n",
        "    self.apply(self._init_weight)\n",
        "    # param\n",
        "    self.time_steps=time_steps\n",
        "    beta=torch.linspace(beta_s,beta_e,time_steps)\n",
        "    alpha=1-beta\n",
        "    self.cum_prod_alpha=np.cumprod(alpha)\n",
        "    self.cum_prod_alpha_prev=np.append(1,alpha[:-1])\n",
        "    self.sqrt_cum_prod_alpha=torch.tensor(np.sqrt(self.cum_prod_alpha),dtype=torch.float32)\n",
        "    self.sqrt_one_cum_prod_alpha=torch.tensor(np.sqrt(1-self.cum_prod_alpha),dtype=torch.float32)\n",
        "    self.optim=torch.optim.Adam(self.parameters(),lr=3e-4)\n",
        "    self.posterior_mean_coef1=torch.tensor(beta*np.sqrt(self.cum_prod_alpha_prev)/(1-self.cum_prod_alpha),dtype=torch.float32)\n",
        "    self.posterior_mean_coef2=torch.tensor((1-self.cum_prod_alpha_prev)*np.sqrt(alpha)/(1-self.cum_prod_alpha),dtype=torch.float32)\n",
        "    self.sqrt_recip_alphas_cumprod=torch.tensor(np.sqrt(1/self.cum_prod_alpha),dtype=torch.float32)\n",
        "    self.sqrt_recipm1_alphas_cumprod=torch.tensor(np.sqrt(1/self.cum_prod_alpha-1),dtype=torch.float32)\n",
        "    self.posterior_variance=beta*(1-self.cum_prod_alpha_prev)/(1-self.cum_prod_alpha)\n",
        "    self.posterior_log_variance_clipped=torch.tensor(np.maximum(self.posterior_variance,1e-20),dtype=torch.float32)\n",
        "\n",
        "  def p_sample(self,x,t,c):\n",
        "    b=x.shape[0]\n",
        "    noise=torch.randn_like(x)\n",
        "    model_mean,_,model_log_var=self.p_mean_variance(x,t,c,noise)\n",
        "    nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))\n",
        "    return model_mean + nonzero_mask * (0.5 * model_log_var).exp() * noise\n",
        "\n",
        "  def q_posterior(self, x_start, x_t, t):\n",
        "      posterior_mean = (\n",
        "              self.extract_into_tensor(self.posterior_mean_coef1, t, x_t.shape) * x_start +\n",
        "              self.extract_into_tensor(self.posterior_mean_coef2, t, x_t.shape) * x_t\n",
        "      )\n",
        "      posterior_variance = self.extract_into_tensor(self.posterior_variance, t, x_t.shape)\n",
        "      posterior_log_variance_clipped = self.extract_into_tensor(self.posterior_log_variance_clipped, t, x_t.shape)\n",
        "      return posterior_mean, posterior_variance, posterior_log_variance_clipped\n",
        "\n",
        "  def predict_start_from_noise(self, x_t, t, noise):\n",
        "    print('t',t)\n",
        "    print('x_t',x_t.shape)\n",
        "    print('sqrt_recipm1_alphas_cumprod',self.sqrt_recipm1_alphas_cumprod.shape)\n",
        "    print('noise',noise.shape)\n",
        "    print('x_t shape',x_t.shape)\n",
        "    out=(\n",
        "            self.extract_into_tensor(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t -\n",
        "            self.extract_into_tensor(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise\n",
        "    )\n",
        "\n",
        "    return out\n",
        "\n",
        "  def p_mean_variance(self, x, t, c,clip_denoised: bool):\n",
        "      model_out,_ = self(x, t,c)\n",
        "      x_recon = self.predict_start_from_noise(x, t=t, noise=model_out)\n",
        "      model_mean, posterior_variance, posterior_log_variance = self.q_posterior(x_start=x_recon, x_t=x, t=t)\n",
        "      return model_mean, posterior_variance, posterior_log_variance\n",
        "\n",
        "  def extract_into_tensor(self,a, t, x_shape):\n",
        "    b, *_ = t.shape\n",
        "    print('extract',t,b)\n",
        "    t=t.long().view(-1)\n",
        "    out = a.gather(-1, t)\n",
        "    print('extract',out)\n",
        "    print(out.reshape(b, *((1,) * (len(x_shape) - 1))))\n",
        "    return out.reshape(b, *((1,) * (len(x_shape) - 1)))\n",
        "\n",
        "  def q_sample(self,x,t,noise):\n",
        "    return self.extract_into_tensor(self.sqrt_cum_prod_alpha,t,x.shape)*x+self.extract_into_tensor(self.sqrt_one_cum_prod_alpha,t,x.shape)*noise\n",
        "\n",
        "  def p_loss(self,x,t,c,noise):\n",
        "    x_noise=self.diffusion(x,t,noise)\n",
        "    pred,_=self(x_noise,t,c)\n",
        "    loss=torch.nn.functional.mse_loss(pred,noise,reduction='none').mean()\n",
        "    return loss\n",
        "\n",
        "  def diffusion(self,x,t,noise):\n",
        "    bs=x.shape[0]\n",
        "    x_noise=self.q_sample(x,t,noise)\n",
        "    return x_noise\n",
        "\n",
        "  def _init_weight(self,m):\n",
        "    if isinstance(m,nn.LayerNorm):\n",
        "      nn.init.constant_(m.bias,0)\n",
        "      nn.init.constant_(m.weight,1.0)\n",
        "\n",
        "  def train(self,x,shape,c):\n",
        "    loss_list=[]\n",
        "      # loader=self.create_loader()\n",
        "      # for x in tqdm(loader):\n",
        "    bs=x.shape[0]\n",
        "    t=torch.randint(0,self.time_steps,(bs,))\n",
        "    noise=torch.randn_like(x)\n",
        "    loss=self.p_loss(x,t,c,noise)\n",
        "    loss_value = loss.item() if hasattr(loss, \"item\") else float(loss)\n",
        "    logging.info(\"loss:{0}\".format(loss_value))\n",
        "    self.optim.zero_grad()\n",
        "    loss.backward()\n",
        "    self.optim.step()\n",
        "\n",
        "\n",
        "      # img = self.sample_loop(shape)\n",
        "      # grid=make_grid(img,nrow=shape[0])\n",
        "      # grid = grid.permute(1, 2, 0).cpu().numpy()\n",
        "      # # 显示\n",
        "      # plt.figure(figsize=(12, 6))\n",
        "      # plt.imshow(grid)\n",
        "      # plt.axis('off')  # 不显示坐标轴\n",
        "      # plt.show()\n",
        "\n",
        "    img=self.sample_loop(shape)\n",
        "    return img,loss_value\n",
        "\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def sample_loop(self, shape):\n",
        "    img = torch.randn(shape)  # 确保到GPU上\n",
        "    # c=random.randint(0,self.num_class-1)\n",
        "    c=1\n",
        "    for t in reversed(range(self.time_steps)):\n",
        "      t_batch = torch.full((img.shape[0],), t,dtype=torch.long)\n",
        "      c_batch = torch.full((img.shape[0],), c,dtype=torch.long)\n",
        "      img = self.p_sample(img, t_batch,c_batch)\n",
        "    img = torch.clamp(img, 0, 1)\n",
        "    return img\n",
        "\n",
        "  '''\n",
        "  x:b,c,h,w\n",
        "  '''\n",
        "  def forward(self,x,t,c):\n",
        "\n",
        "    b,ch,h,w=x.shape\n",
        "    # bs,2,embed\n",
        "    cond_emb=self.cond_emb(t,c)\n",
        "    # b,n,embed_dim\n",
        "    x=self.patch(x)\n",
        "    b,n,embed_dim=x.shape\n",
        "    print('patch',x.shape)\n",
        "    c=None\n",
        "    if self.types=='in_context':\n",
        "      for block in self.blocks:\n",
        "        x=block(torch.cat((x,cond_emb),dim=1),c)\n",
        "    else:\n",
        "      for block in self.blocks:\n",
        "        x=block(x,cond_emb)\n",
        "    x=self.linear(self.norm(x)).view(b,-1,2*ch,self.patch_dim**2).permute(0,2,1,3).contiguous().view(b,2*ch,-1).view(b,2*ch,h,-1)\n",
        "    pred_n,cov=x.chunk(2,dim=1)\n",
        "    return pred_n,cov"
      ],
      "metadata": {
        "id": "c6UuXtm2EvBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.utils import make_grid\n",
        "from torchvision import datasets,transforms\n",
        "class UpBlock(nn.Module):\n",
        "    def __init__(self,in_channel,out_channel,time_channel,head_num,has_attention=False):\n",
        "        super().__init__()\n",
        "        self.residual=ResidualBlock(in_channel,out_channel,time_channel)\n",
        "        if has_attention:\n",
        "            self.attention=Attention(head_num,out_channel)\n",
        "        else:\n",
        "            self.attention=nn.Identity()\n",
        "    def forward(self,img,t):\n",
        "        out=self.residual(img,t)\n",
        "        out=self.attention(out)\n",
        "        return out\n",
        "def custom_collate_fn(batch):\n",
        "    images=[x[0] for x in batch]\n",
        "    return torch.stack(images)\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self,z_ch,embed_dim,ch_mult=(1,2,2,4),img_ch=3,in_channel=64,blocks=2,head_num=8):\n",
        "        super().__init__()\n",
        "        down=[]\n",
        "        layers=len(ch_mult)\n",
        "        self.conv1=nn.Conv2d(img_ch,in_channel,kernel_size=(3,3),padding=(1,1))\n",
        "        self.time=TimeEmbedding(in_channel*4)\n",
        "        n_channel=in_channel\n",
        "        for i in range(layers):\n",
        "            out_ch=ch_mult[i]*in_channel\n",
        "            for _ in range(blocks):\n",
        "                down.append(DownBlock(in_channel,out_ch,n_channel*4,head_num))\n",
        "                in_channel=out_ch\n",
        "            if i<layers-1:\n",
        "                down.append(DownSampleBlock(out_ch))\n",
        "        self.down=nn.ModuleList(down)\n",
        "\n",
        "        self.middle=MiddleBlock(out_ch,out_ch,n_channel*4,head_num)\n",
        "        self.ins=nn.InstanceNorm2d(in_channel)\n",
        "        self.act=nn.ELU()\n",
        "        self.conv2=nn.Conv2d(in_channel,2*z_ch,kernel_size=(3,3),padding=(1,1))\n",
        "        self.dis=nn.Conv2d(2*z_ch,2*embed_dim,1)\n",
        "    def sample(self,z):\n",
        "      mean,log_var=self.dis(z).chunk(2,dim=1)\n",
        "      std=torch.exp(0.5*log_var)\n",
        "      x=mean+torch.randn(mean.shape)*std\n",
        "      return x\n",
        "    def forward(self,x,t):\n",
        "        out=self.conv1(x)\n",
        "        if t is not None:\n",
        "          t=self.time(t)\n",
        "        record=[out]\n",
        "        for down in self.down:\n",
        "            out=down(out,t)\n",
        "            print('out')\n",
        "            record.append(out)\n",
        "        out=self.middle(out,t)\n",
        "        out=self.conv2(self.act(self.ins(out)))\n",
        "        return out\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self,z_ch,ch_multi=(1,2,2,4),img_ch=3,in_channel=64,blocks=2,head_num=8):\n",
        "        super().__init__()\n",
        "        layers=len(ch_multi)\n",
        "        self.conv1=nn.Conv2d(z_ch,in_channel,kernel_size=(3,3),padding=(1,1))\n",
        "        self.time=TimeEmbedding(in_channel*4)\n",
        "        n_channel=in_channel\n",
        "        self.middle=MiddleBlock(in_channel,in_channel,n_channel*4,head_num)\n",
        "        up=[]\n",
        "        for i in range(layers):\n",
        "            out_ch=in_channel\n",
        "            for _ in range(blocks):\n",
        "                up.append(UpBlock(in_channel,out_ch,n_channel*4,head_num))\n",
        "            out_ch=in_channel//ch_multi[layers-1-i]\n",
        "            up.append(UpBlock(in_channel,out_ch,n_channel*4,head_num))\n",
        "            in_channel=out_ch\n",
        "            if i<layers-1:\n",
        "                up.append(UpSampleBlock(in_channel))\n",
        "        self.up=nn.ModuleList(up)\n",
        "        self.ins=nn.InstanceNorm2d(in_channel)\n",
        "        self.act=nn.ELU()\n",
        "        self.conv2=nn.Conv2d(in_channel,img_ch,kernel_size=(3,3),padding=(1,1))\n",
        "    def forward(self,x,t):\n",
        "        out=self.conv1(x)\n",
        "        if t is not None:\n",
        "          t=self.time(t)\n",
        "        out=self.middle(out,t)\n",
        "        for up in self.up:\n",
        "          out=up(out,t)\n",
        "        out=self.conv2(self.act(self.ins(out)))\n",
        "        return out\n",
        "\n",
        "class DiTWrapper(nn.Module):\n",
        "  def __init__(self,encoder_config,decoder_config,dit_config,img_path,bs):\n",
        "    super().__init__()\n",
        "    self.encoder=Encoder(**encoder_config)\n",
        "    self.decoder=Decoder(**decoder_config)\n",
        "    self.encoder.requires_grad_(False)\n",
        "    self.decoder.requires_grad_(False)\n",
        "    self.DiT=DiT(**dit_config)\n",
        "    self.bs=bs\n",
        "    self.img_path=img_path\n",
        "  def frozen(self,model):\n",
        "    for param in model.parameters():\n",
        "      param.requires_grad=False\n",
        "\n",
        "  def create_loader(self):\n",
        "    if datasets=='mnist':\n",
        "      transform=transforms.Compose([\n",
        "          transforms.ToTensor(),\n",
        "      ])\n",
        "      train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "      loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "      # test_dataset  = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "    else:\n",
        "      transform=transforms.Compose([\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Resize(280),\n",
        "          transforms.CenterCrop(256),\n",
        "      ])\n",
        "      logging.info('start transform')\n",
        "      dataset=datasets.ImageFolder(self.img_path,transform=transform)\n",
        "      logging.info('finish transform')\n",
        "      bs=self.bs\n",
        "      # num_workers=self.model_config.run.num_workers\n",
        "      loader=iter(DataLoader(dataset,batch_size=bs,collate_fn=custom_collate_fn,num_workers=1,pin_memory=True))\n",
        "    return loader\n",
        "\n",
        "  def train(self,c,epochs,shape):\n",
        "    loss_list=[]\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "      create_loader=self.create_loader()\n",
        "      for x in tqdm(create_loader):\n",
        "        loss=self(x,c,shape)\n",
        "        loss_list.append(loss)\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.plot(loss_list)\n",
        "    plt.title(\"Loss Curve\")\n",
        "    plt.xlabel(\"Iteration\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "  def forward(self,x,c,shape):\n",
        "    t=None\n",
        "    # encoder=self.frozen(self.encoder)\n",
        "    # print(type(encoder))\n",
        "    # with torch.no_grad():\n",
        "    #   e=self.encoder(x,t)\n",
        "    # z=self.encoder.sample(e)\n",
        "    # z_rec,loss=self.DiT.train(z,shape,c)\n",
        "    z_rec,loss=self.DiT.train(x,shape,c)\n",
        "\n",
        "    # with torch.no_grad():\n",
        "    #   x_rec=self.decoder(z_rec,t)\n",
        "    # grid=make_grid(x_rec,nrow=shape[0])\n",
        "    grid=make_grid(z_rec,nrow=shape[0])\n",
        "    grid = grid.permute(1, 2, 0).detach().cpu().numpy()\n",
        "    # 显示\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.imshow(grid)\n",
        "    plt.axis('off')  # 不显示坐标轴\n",
        "    plt.show()\n",
        "    return loss"
      ],
      "metadata": {
        "id": "Mfz_jGI4Ey8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from omegaconf import OmegaConf\n",
        "img_path='/content/drive/MyDrive/filter/'\n",
        "conf=OmegaConf.load('/content/drive/MyDrive/DiT.yaml')\n",
        "print(conf.model.DiT)\n",
        "model=DiTWrapper(conf.model.Encoder,conf.model.Decoder,conf.model.DiT,img_path,16)\n",
        "model.train(torch.tensor([1]*16,dtype=torch.long),16,(16,4,32,32))"
      ],
      "metadata": {
        "id": "q4bAG29-E1uh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}